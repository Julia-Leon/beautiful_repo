{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cleared-month",
   "metadata": {},
   "source": [
    "# Binary classification with Logistic regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0584910",
   "metadata": {},
   "source": [
    "## 1. Getting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-planner",
   "metadata": {},
   "source": [
    "### 1.1. Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29690e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "password=getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-cloud",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1.2. Connection to sql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection string\n",
    "connection_string = 'mysql+pymysql://root:'+password+'@localhost/bank'\n",
    "engine= create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb10282",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### 1.3. Query as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad17da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_sql_query('''\n",
    "select l.loan_id, l.status, count(distinct t.trans_id) as nooftrans,\n",
    "DATEDIFF(19981231, convert(a.date,date)) as ageindays, \n",
    "d.A12 as 95unemp, d.A13 as 96unemp, dp.type,\n",
    "l.amount as loanamount, c.birth_number, d.A15 as crime95, d.A16 as crime96,\n",
    "round((l.amount-l.payments)/l.amount,2) as ratiopaid\n",
    "from loan l\n",
    "left join trans t\n",
    "using(account_id)\n",
    "left join account a\n",
    "using(account_id)\n",
    "left join district d\n",
    "on a.district_id = d.A1\n",
    "left join disp dp\n",
    "on a.account_id= dp.account_id \n",
    "left join client c\n",
    "using(client_id)\n",
    "where l.status in('A','B') and dp.type='OWNER'\n",
    "group by loan_id, l.amount, status, d.A12, d.A13, c.birth_number, d.A15, d.A16, DATEDIFF(19981231, convert(a.date,date)),\n",
    " dp.type, round((l.amount-l.payments)/l.amount,2)\n",
    "''', engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77768391",
   "metadata": {},
   "source": [
    "\n",
    "#### - verify the dataframe works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-jamaica",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## 2. EDA - exploratory data analysis - get to know the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6db801",
   "metadata": {},
   "source": [
    "### 2.1. Check what columns look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "#after looking at that we can decide droping loan_id \n",
    "# or changing birth data type, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd44be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.birth_number.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0886f95",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2.2. Histograms or Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0abde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df,x = 'nooftrans', hue='status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153c0a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='loanamount', y='status', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cb5e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df['ageindays'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ffe825",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.kdeplot(df['95unemp'], shade=True, color=\"r\")\n",
    "fig = sns.kdeplot(df['96unemp'], shade=True, color=\"b\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d139d943",
   "metadata": {},
   "source": [
    "### 2.3. Check for multicollinearity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for logistic regression we don't really need to check \n",
    "#for multicollinearity, but it is a good practice to do it\n",
    "df.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr(method = 'pearson')\n",
    "fig,ax=plt.subplots(figsize=(10,8))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "ax=sns.heatmap(corr_matrix, mask=mask, annot=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de019eeb",
   "metadata": {},
   "source": [
    "### 2.4. Clean and wrangling steps \n",
    "\n",
    "- clean /wrangling steps suggested :\n",
    "- bucket into categories any fields \n",
    "- should we drop any columns ? (iterative process)\n",
    "- extract gender from birth_number\n",
    "- data type changes \n",
    "- drop highly correlated features \n",
    "- create avg of criminality / unempl rate \n",
    "- crime - divide by population \n",
    "- bring in any missing fields \n",
    "- change unempl into HML \n",
    "- change crime numbers into one column - sum the two columns \n",
    "- bring in the C and D statuses - and then using a function map to good or bad \n",
    "- OR multi class regression ?\n",
    "- k symbol might be worth including \n",
    "- loan duration \n",
    "\n",
    "- feature engineering - take the columns and make more useful \n",
    "\n",
    "\n",
    "\n",
    "### 2.5. Split the data into num and cat --- > diff options cleaning / scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['loan_id' ,'type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e29550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0608477c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3. Pre processing     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff11c76e",
   "metadata": {},
   "source": [
    "### 3.1. Label / encode categorical columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df.select_dtypes(include=object)\n",
    "cat.head()\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96efc036",
   "metadata": {},
   "source": [
    "- we can select categoricals, but this time asigning a num to each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f55b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical = pd.get_dummies(cat, columns = ['status'], drop_first = True)\n",
    "categorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf4dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558b152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=Normalizer().fit(X)\n",
    "scaled=scaler.transform(X)\n",
    "scaled_X=pd.DataFrame(scaled)\n",
    "scaled_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-teaching",
   "metadata": {},
   "source": [
    "### 3.2. Split off the dependant variable (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = dependentvariable - status\n",
    "\n",
    "y = categorical['status_B']\n",
    "\n",
    "# independent variables are scaled_X\n",
    "X = scaled_X #big X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-article",
   "metadata": {},
   "source": [
    "### 3.3. Train test split, get LOG REG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-moore",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ruled-management",
   "metadata": {},
   "source": [
    "## 4. Apply model and train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = LogisticRegression(solver='liblinear', multi_class='ovr').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47151ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-depth",
   "metadata": {},
   "source": [
    "### 4.1. Evaluate accuracy and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = classification.predict_proba(X_test)\n",
    "preds = probabilities[:,1]\n",
    "import sklearn.metrics as metrics\n",
    "fpr, tpr, treshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-booking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-solid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faa370ec",
   "metadata": {},
   "source": [
    "#### next steps\n",
    "\n",
    "+ Visualise the accuracy of the predictions in some ways \n",
    "\n",
    "+ also think about - is there something I could do to improve my model accuracy?? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-mother",
   "metadata": {},
   "source": [
    "### 4.2. Visualising accuracy - ROC / AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc curve plot\n",
    "plt.title('receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, label = 'AUC' %roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af0bee2",
   "metadata": {},
   "source": [
    "#roc curve plot \n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr,tpr, label='AUC'%roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee75d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6e6812c",
   "metadata": {},
   "source": [
    "### 4.3. Visualising accuracy - Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0557d3b",
   "metadata": {},
   "source": [
    "##### definitions \n",
    "+ tpr = true positive rate \n",
    "+ fpr = false positive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2529a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = classification.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3676dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)\n",
    "confusion_matrix(y_test, predictions)\n",
    "plot_confusion_matrix(classification, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec01157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "physical-aaron",
   "metadata": {},
   "source": [
    "### 4.5. Data is highly imbalanced\n",
    "\n",
    "this is affecting the accuracy of our predictions \n",
    "- what can be done to resolve that ?\n",
    "\n",
    "\n",
    "+ option 1 - SMOTE \n",
    "\n",
    "+ option 2 - TOMEK LINKS \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
